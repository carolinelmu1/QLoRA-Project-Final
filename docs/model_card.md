# Model Card: QLoRA Fine-Tuned GPT-2 Medium

## Model Details

**Model Name:** QLoRA-GPT2-Medium-Alpaca  
**Version:** 1.0 (Diagnostic Research Implementation)  
**Date:** December 2025  
**Organization:** Vanderbilt University DS 5690 Course Project  
**Author:** Caroline Ellis

### Model Description

This model is GPT-2 Medium (355M parameters) fine-tuned using QLoRA (Quantized Low-Rank Adaptation) for instruction-following tasks. The base model's weights are quantized to 4-bit precision (NF4) while trainable adapter matrices remain in high precision (BF16).

**Architecture:**
- Base: GPT-2 Medium
- Parameters: 355 million
- Layers: 24
- Hidden size: 1024
- Attention heads: 16
- Vocabulary size: 50,257

**Adaptation Method:**
- Technique: QLoRA (4-bit quantization + LoRA adapters)
- Rank (r): [Varies: 2, 4, 8, or 16 depending on variant]
- Target modules: c_attn (Query, Key, Value projections)
- LoRA alpha: 16
- LoRA dropout: 0.05

## Intended Use

### Primary Intended Uses

1. **Research and Education:**
   - Understanding parameter-efficient fine-tuning mechanisms
   - Studying quantization effects on model performance
   - Teaching material for NLP and deep learning courses

2. **Diagnostic Analysis:**
   - Benchmarking QLoRA against standard LoRA
   - Investigating rank threshold effects
   - Analyzing layer sensitivity to quantization

3. **Prototyping:**
   - Rapid iteration on instruction-following systems
   - Testing prompt engineering strategies
   - Exploring low-resource deployment scenarios

### Out-of-Scope Uses

❌ **Not Intended For:**
- Production deployment without extensive validation
- High-stakes applications (medical diagnosis, legal advice, financial decisions)
- Content moderation or safety-critical systems
- Real-time applications requiring guaranteed latency
- Generating factual information without verification

## Training Data

**Dataset:** Stanford Alpaca  
**Size Used:** 1,000 samples (subset for diagnostic experiments)  
**Full Dataset:** 52,000 instruction-response pairs  
**Source:** Self-Instruct methodology using GPT-3.5-turbo  
**License:** CC BY NC 4.0 (Non-commercial use only)

**Data Format:**
```
### Instruction:
{instruction_text}

### Input: (optional)
{input_text}

### Response:
{output_text}
```

**Task Distribution:** Diverse instructions including:
- Text generation and completion
- Question answering
- Translation
- Summarization
- Classification and categorization
- Code generation (limited)

## Training Procedure

**Training Configuration:**
- Framework: HuggingFace Transformers + PEFT
- Optimizer: AdamW
- Learning rate: 2×10⁻⁴
- Batch size: 4
- Max training steps: 200
- Gradient accumulation: 1
- Compute dtype: BF16
- Hardware: Google Colab (NVIDIA T4, 16GB VRAM)

**Quantization Details:**
- Method: 4-bit NormalFloat (NF4)
- Blocksize: 64
- Double quantization: Enabled
- Compute dtype: BF16

## Evaluation

### Metrics

1. **Memory Efficiency:**
   - Peak GPU memory (MB)
   - Measured via `torch.cuda.max_memory_allocated()`

2. **Performance Preservation:**
   - Token match rate (greedy decoding)
   - Embedding cosine similarity
   - Training loss

3. **Training Efficiency:**
   - Time per training step (seconds)

### Results

[TODO: Fill in after experiments complete]

**Memory Reduction:** QLoRA achieves [X]% memory reduction vs. 16-bit LoRA

**Performance:** Cosine similarity with 16-bit LoRA baseline: [X] (threshold: ≥0.95)

**Optimal Rank:** r=[X] provides best balance of performance and efficiency

## Limitations

### Known Issues

1. **Model Size Constraints:**
   - GPT-2 Medium (355M) is significantly smaller than modern LLMs (7B+)
   - May not generalize findings to larger models
   - Limited context window (1024 tokens)

2. **Training Data Limitations:**
   - Only 1,000 samples used for diagnostic purposes
   - Not representative of full fine-tuning performance
   - May overfit to limited training distribution

3. **Quantization Effects:**
   - 4-bit quantization introduces information loss
   - May affect rare tokens or edge cases disproportionately
   - Long-term drift effects unknown

4. **Task Specificity:**
   - Fine-tuned only on instruction-following
   - May not perform well on other tasks (e.g., code generation, reasoning)

### Bias and Fairness

**Inherited Biases:**
- GPT-2 trained on Reddit data (demographic skew toward young, male, Western users)
- Known biases in gender, race, religion, and political orientation
- Alpaca data generated by GPT-3.5 (inherits OpenAI model biases)

**Quantization Impact on Bias:**
- Unknown whether 4-bit quantization affects fairness metrics
- Potential for amplification or reduction of biases (requires further study)

## Ethical Considerations

### Potential Harms

1. **Misinformation:** May generate plausible but incorrect information
2. **Toxic Content:** Can produce harmful outputs if prompted inappropriately
3. **Privacy:** May memorize and regurgitate training data
4. **Bias Amplification:** May reinforce societal biases present in training data

### Mitigation Strategies

1. **Content Filtering:** Implement input/output safety classifiers
2. **Human Oversight:** Require human review for high-stakes applications
3. **Usage Monitoring:** Log and analyze usage patterns for abuse detection
4. **Access Control:** Deploy behind authentication and rate limiting
5. **Transparency:** Clearly communicate limitations to end users

## Licenses

**Code:** MIT License  
**Base Model:** OpenAI GPT-2 (MIT License)  
**Training Data:** CC BY NC 4.0 (Non-commercial use only)  

**IMPORTANT:** Due to Alpaca dataset license, this model may only be used for **non-commercial purposes**.

## Citation

If you use this model or code in your research, please cite:

```bibtex
@misc{ellis2025qlora_diagnostic,
  author = {Ellis, Caroline},
  title = {QLoRA Diagnostic Analysis: When Does 4-Bit Quantization Preserve Quality?},
  year = {2025},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/[YOUR_USERNAME]/QLoRA-Project}}
}
```

**Original Papers:**
```bibtex
@article{dettmers2023qlora,
  title={QLoRA: Efficient Finetuning of Quantized LLMs},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={NeurIPS},
  year={2023}
}

@article{hu2021lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={ICLR},
  year={2022}
}
```

## Model Card Contact

**Maintainer:** Caroline Ellis  
**Email:** [your_email@vanderbilt.edu]  
**GitHub:** [https://github.com/[YOUR_USERNAME]/QLoRA-Project]

**Last Updated:** December 2025