{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc315b4e",
   "metadata": {},
   "source": [
    "# QLoRA Diagnostic Analysis - Part 1: Baseline LoRA (16-bit)\n",
    "\n",
    "## Objective\n",
    "Establish baseline performance using standard LoRA with 16-bit precision on GPT-2 Medium (355M parameters). This serves as the reference point for comparing against QLoRA's 4-bit quantization.\n",
    "\n",
    "## Key Questions\n",
    "1. What is the memory requirement for 16-bit LoRA fine-tuning?\n",
    "2. How does performance scale with different ranks (r ‚àà {2, 4, 8, 16})?\n",
    "3. What is the training efficiency (time per step)?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc94e73e",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3217c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -q transformers datasets accelerate peft bitsandbytes matplotlib seaborn pandas numpy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utilities\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add src to path (if running in Colab, upload src files first)\n",
    "# sys.path.append('./src')\n",
    "\n",
    "# Import custom modules\n",
    "from model_utils import (\n",
    "    load_base_model_16bit,\n",
    "    setup_lora_16bit,\n",
    "    get_model_memory_usage,\n",
    "    print_model_architecture,\n",
    "    clear_memory\n",
    ")\n",
    "\n",
    "from training import (\n",
    "    prepare_alpaca_dataset,\n",
    "    train_model,\n",
    "    run_experiment\n",
    ")\n",
    "\n",
    "from visualization import (\n",
    "    plot_memory_comparison,\n",
    "    create_results_table,\n",
    "    print_diagnostic_summary\n",
    ")\n",
    "\n",
    "print(f\"‚úì PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c82c74",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental configuration\n",
    "MODEL_NAME = \"gpt2-medium\"  # 355M parameters\n",
    "NUM_SAMPLES = 1000          # Small dataset for quick diagnostic experiments\n",
    "MAX_STEPS = 200             # Training steps per experiment\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 2e-4\n",
    "\n",
    "# Ranks to test\n",
    "RANKS_TO_TEST = [2, 4, 8, 16]\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"./results_baseline_lora\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Training samples: {NUM_SAMPLES}\")\n",
    "print(f\"  Max steps: {MAX_STEPS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Ranks to test: {RANKS_TO_TEST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086d92e",
   "metadata": {},
   "source": [
    "## 3. Run Baseline LoRA Experiments\n",
    "\n",
    "We'll train LoRA with different ranks to establish baseline performance and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "results_list = []\n",
    "\n",
    "for rank in RANKS_TO_TEST:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Running LoRA (16-bit) with rank r={rank}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    try:\n",
    "        result, model, tokenizer = run_experiment(\n",
    "            model_name=MODEL_NAME,\n",
    "            quantization=\"16bit\",\n",
    "            rank=rank,\n",
    "            num_samples=NUM_SAMPLES,\n",
    "            max_steps=MAX_STEPS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            output_dir=OUTPUT_DIR\n",
    "        )\n",
    "        \n",
    "        results_list.append(result)\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        del model\n",
    "        del tokenizer\n",
    "        clear_memory()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with rank {rank}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n‚úì All experiments complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d2cb0",
   "metadata": {},
   "source": [
    "## 4. Results Analysis\n",
    "\n",
    "### 4.1 Create Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ee6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results table\n",
    "results_df = create_results_table(\n",
    "    results_list,\n",
    "    save_path=f\"{OUTPUT_DIR}/baseline_lora_results.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nüìä BASELINE LoRA RESULTS\")\n",
    "print(\"=\"*80)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81458099",
   "metadata": {},
   "source": [
    "### 4.2 Memory Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b0c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot memory usage by rank\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(results_df['rank'], results_df['peak_memory_mb'])\n",
    "plt.xlabel('LoRA Rank (r)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Peak GPU Memory (MB)', fontsize=12, fontweight='bold')\n",
    "plt.title('Baseline LoRA (16-bit): Memory Usage by Rank', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/baseline_memory_by_rank.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average memory usage: {results_df['peak_memory_mb'].mean():.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe92669f",
   "metadata": {},
   "source": [
    "### 4.3 Training Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time per step\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(results_df['rank'], results_df['time_per_step'])\n",
    "plt.xlabel('LoRA Rank (r)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Time per Step (seconds)', fontsize=12, fontweight='bold')\n",
    "plt.title('Baseline LoRA (16-bit): Training Speed by Rank', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/baseline_speed_by_rank.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average time per step: {results_df['time_per_step'].mean():.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f7fc9",
   "metadata": {},
   "source": [
    "## 5. Key Findings\n",
    "\n",
    "### TODO: Fill in after running experiments\n",
    "\n",
    "**Memory Usage:**\n",
    "- Rank 2: [TODO: FILL] MB  \n",
    "- Rank 4: [TODO: FILL] MB  \n",
    "- Rank 8: [TODO: FILL] MB  \n",
    "- Rank 16: [TODO: FILL] MB  \n",
    "\n",
    "**Training Speed:**\n",
    "- Average time per step: [TODO: FILL]s  \n",
    "\n",
    "**Observations:**\n",
    "- [TODO: Document any trends observed]  \n",
    "- [TODO: Note any unexpected behavior]  \n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "- Proceed to Part 2: Implement QLoRA (4-bit) and compare results  \n",
    "- Use these baseline metrics as reference for quantization impact analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e3dac",
   "metadata": {},
   "source": [
    "## 6. Save Results for Next Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for comparison in subsequent notebooks\n",
    "import pickle\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/baseline_results.pkl\", 'wb') as f:\n",
    "    pickle.dump(results_list, f)\n",
    "\n",
    "print(f\"‚úì Results saved to {OUTPUT_DIR}/baseline_results.pkl\")\n",
    "print(\"\\nüéâ Baseline LoRA experiments complete!\")\n",
    "print(\"üìù Proceed to notebook 02_qlora_implementation.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
