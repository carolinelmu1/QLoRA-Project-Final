{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.7761989342806395,
  "eval_steps": 50,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017761989342806393,
      "grad_norm": 0.322981595993042,
      "learning_rate": 0.00018,
      "loss": 3.1119,
      "step": 10
    },
    {
      "epoch": 0.035523978685612786,
      "grad_norm": 0.8073226809501648,
      "learning_rate": 0.00019818181818181821,
      "loss": 3.1303,
      "step": 20
    },
    {
      "epoch": 0.05328596802841918,
      "grad_norm": 0.3292853534221649,
      "learning_rate": 0.00019616161616161618,
      "loss": 2.8524,
      "step": 30
    },
    {
      "epoch": 0.07104795737122557,
      "grad_norm": 0.37592175602912903,
      "learning_rate": 0.00019414141414141417,
      "loss": 2.6617,
      "step": 40
    },
    {
      "epoch": 0.08880994671403197,
      "grad_norm": 0.43944934010505676,
      "learning_rate": 0.00019212121212121213,
      "loss": 2.395,
      "step": 50
    },
    {
      "epoch": 0.08880994671403197,
      "eval_loss": 2.1806142330169678,
      "eval_runtime": 20.0292,
      "eval_samples_per_second": 24.964,
      "eval_steps_per_second": 3.145,
      "step": 50
    },
    {
      "epoch": 0.10657193605683836,
      "grad_norm": 0.3571276366710663,
      "learning_rate": 0.00019010101010101012,
      "loss": 2.2553,
      "step": 60
    },
    {
      "epoch": 0.12433392539964476,
      "grad_norm": 0.33574503660202026,
      "learning_rate": 0.00018808080808080808,
      "loss": 2.0941,
      "step": 70
    },
    {
      "epoch": 0.14209591474245115,
      "grad_norm": 0.39752015471458435,
      "learning_rate": 0.00018606060606060607,
      "loss": 2.1176,
      "step": 80
    },
    {
      "epoch": 0.15985790408525755,
      "grad_norm": 0.3313269019126892,
      "learning_rate": 0.00018404040404040406,
      "loss": 2.126,
      "step": 90
    },
    {
      "epoch": 0.17761989342806395,
      "grad_norm": 0.3190056383609772,
      "learning_rate": 0.00018202020202020202,
      "loss": 2.0668,
      "step": 100
    },
    {
      "epoch": 0.17761989342806395,
      "eval_loss": 1.9630036354064941,
      "eval_runtime": 20.0333,
      "eval_samples_per_second": 24.958,
      "eval_steps_per_second": 3.145,
      "step": 100
    },
    {
      "epoch": 0.19538188277087035,
      "grad_norm": 0.3082979619503021,
      "learning_rate": 0.00018,
      "loss": 2.0908,
      "step": 110
    },
    {
      "epoch": 0.21314387211367672,
      "grad_norm": 0.39509743452072144,
      "learning_rate": 0.00017797979797979797,
      "loss": 2.0575,
      "step": 120
    },
    {
      "epoch": 0.23090586145648312,
      "grad_norm": 0.28981155157089233,
      "learning_rate": 0.00017595959595959596,
      "loss": 2.0699,
      "step": 130
    },
    {
      "epoch": 0.24866785079928952,
      "grad_norm": 0.37267836928367615,
      "learning_rate": 0.00017393939393939395,
      "loss": 2.0348,
      "step": 140
    },
    {
      "epoch": 0.2664298401420959,
      "grad_norm": 0.3944452404975891,
      "learning_rate": 0.00017191919191919192,
      "loss": 2.0786,
      "step": 150
    },
    {
      "epoch": 0.2664298401420959,
      "eval_loss": 1.922463059425354,
      "eval_runtime": 20.0453,
      "eval_samples_per_second": 24.944,
      "eval_steps_per_second": 3.143,
      "step": 150
    },
    {
      "epoch": 0.2841918294849023,
      "grad_norm": 0.29571300745010376,
      "learning_rate": 0.0001698989898989899,
      "loss": 2.0227,
      "step": 160
    },
    {
      "epoch": 0.3019538188277087,
      "grad_norm": 0.3175060749053955,
      "learning_rate": 0.00016787878787878787,
      "loss": 1.9973,
      "step": 170
    },
    {
      "epoch": 0.3197158081705151,
      "grad_norm": 0.3188343644142151,
      "learning_rate": 0.00016585858585858586,
      "loss": 1.9819,
      "step": 180
    },
    {
      "epoch": 0.33747779751332146,
      "grad_norm": 0.3308510482311249,
      "learning_rate": 0.00016383838383838385,
      "loss": 2.0481,
      "step": 190
    },
    {
      "epoch": 0.3552397868561279,
      "grad_norm": 0.32444843649864197,
      "learning_rate": 0.00016181818181818184,
      "loss": 2.0218,
      "step": 200
    },
    {
      "epoch": 0.3552397868561279,
      "eval_loss": 1.8988327980041504,
      "eval_runtime": 20.0358,
      "eval_samples_per_second": 24.955,
      "eval_steps_per_second": 3.144,
      "step": 200
    },
    {
      "epoch": 0.37300177619893427,
      "grad_norm": 0.2939170300960541,
      "learning_rate": 0.00015979797979797983,
      "loss": 1.9802,
      "step": 210
    },
    {
      "epoch": 0.3907637655417407,
      "grad_norm": 0.3395543396472931,
      "learning_rate": 0.0001577777777777778,
      "loss": 2.0105,
      "step": 220
    },
    {
      "epoch": 0.40852575488454707,
      "grad_norm": 0.3665492832660675,
      "learning_rate": 0.00015575757575757578,
      "loss": 2.0463,
      "step": 230
    },
    {
      "epoch": 0.42628774422735344,
      "grad_norm": 0.3268439769744873,
      "learning_rate": 0.00015373737373737374,
      "loss": 2.0013,
      "step": 240
    },
    {
      "epoch": 0.44404973357015987,
      "grad_norm": 0.4528302252292633,
      "learning_rate": 0.00015171717171717173,
      "loss": 1.888,
      "step": 250
    },
    {
      "epoch": 0.44404973357015987,
      "eval_loss": 1.8848072290420532,
      "eval_runtime": 20.0023,
      "eval_samples_per_second": 24.997,
      "eval_steps_per_second": 3.15,
      "step": 250
    },
    {
      "epoch": 0.46181172291296624,
      "grad_norm": 0.34339314699172974,
      "learning_rate": 0.00014969696969696972,
      "loss": 2.0875,
      "step": 260
    },
    {
      "epoch": 0.47957371225577267,
      "grad_norm": 0.34229183197021484,
      "learning_rate": 0.00014767676767676768,
      "loss": 1.9525,
      "step": 270
    },
    {
      "epoch": 0.49733570159857904,
      "grad_norm": 0.4481751322746277,
      "learning_rate": 0.00014565656565656567,
      "loss": 2.058,
      "step": 280
    },
    {
      "epoch": 0.5150976909413855,
      "grad_norm": 0.42162972688674927,
      "learning_rate": 0.00014363636363636363,
      "loss": 1.9231,
      "step": 290
    },
    {
      "epoch": 0.5328596802841918,
      "grad_norm": 0.2797574996948242,
      "learning_rate": 0.00014161616161616162,
      "loss": 1.9712,
      "step": 300
    },
    {
      "epoch": 0.5328596802841918,
      "eval_loss": 1.874861240386963,
      "eval_runtime": 20.0308,
      "eval_samples_per_second": 24.962,
      "eval_steps_per_second": 3.145,
      "step": 300
    },
    {
      "epoch": 0.5506216696269982,
      "grad_norm": 0.3574099838733673,
      "learning_rate": 0.0001395959595959596,
      "loss": 2.0054,
      "step": 310
    },
    {
      "epoch": 0.5683836589698046,
      "grad_norm": 0.37679943442344666,
      "learning_rate": 0.00013757575757575758,
      "loss": 1.8902,
      "step": 320
    },
    {
      "epoch": 0.5861456483126111,
      "grad_norm": 0.46518006920814514,
      "learning_rate": 0.00013555555555555556,
      "loss": 1.9805,
      "step": 330
    },
    {
      "epoch": 0.6039076376554174,
      "grad_norm": 0.39016494154930115,
      "learning_rate": 0.00013353535353535353,
      "loss": 2.1116,
      "step": 340
    },
    {
      "epoch": 0.6216696269982238,
      "grad_norm": 0.4698531925678253,
      "learning_rate": 0.00013151515151515152,
      "loss": 2.2168,
      "step": 350
    },
    {
      "epoch": 0.6216696269982238,
      "eval_loss": 1.8656553030014038,
      "eval_runtime": 20.0199,
      "eval_samples_per_second": 24.975,
      "eval_steps_per_second": 3.147,
      "step": 350
    },
    {
      "epoch": 0.6394316163410302,
      "grad_norm": 0.40204283595085144,
      "learning_rate": 0.00012949494949494948,
      "loss": 1.9034,
      "step": 360
    },
    {
      "epoch": 0.6571936056838366,
      "grad_norm": 0.3523508310317993,
      "learning_rate": 0.00012747474747474747,
      "loss": 1.9936,
      "step": 370
    },
    {
      "epoch": 0.6749555950266429,
      "grad_norm": 0.42206838726997375,
      "learning_rate": 0.00012545454545454546,
      "loss": 1.9019,
      "step": 380
    },
    {
      "epoch": 0.6927175843694494,
      "grad_norm": 0.25632140040397644,
      "learning_rate": 0.00012343434343434345,
      "loss": 1.9921,
      "step": 390
    },
    {
      "epoch": 0.7104795737122558,
      "grad_norm": 0.28814852237701416,
      "learning_rate": 0.00012141414141414142,
      "loss": 1.9092,
      "step": 400
    },
    {
      "epoch": 0.7104795737122558,
      "eval_loss": 1.8562980890274048,
      "eval_runtime": 20.02,
      "eval_samples_per_second": 24.975,
      "eval_steps_per_second": 3.147,
      "step": 400
    },
    {
      "epoch": 0.7282415630550622,
      "grad_norm": 0.2943880558013916,
      "learning_rate": 0.00011939393939393939,
      "loss": 1.9402,
      "step": 410
    },
    {
      "epoch": 0.7460035523978685,
      "grad_norm": 0.44496577978134155,
      "learning_rate": 0.00011737373737373738,
      "loss": 1.885,
      "step": 420
    },
    {
      "epoch": 0.7637655417406749,
      "grad_norm": 0.33169806003570557,
      "learning_rate": 0.00011535353535353537,
      "loss": 1.9033,
      "step": 430
    },
    {
      "epoch": 0.7815275310834814,
      "grad_norm": 0.37710389494895935,
      "learning_rate": 0.00011333333333333334,
      "loss": 1.9049,
      "step": 440
    },
    {
      "epoch": 0.7992895204262878,
      "grad_norm": 0.5143488049507141,
      "learning_rate": 0.00011131313131313133,
      "loss": 1.9823,
      "step": 450
    },
    {
      "epoch": 0.7992895204262878,
      "eval_loss": 1.8501474857330322,
      "eval_runtime": 20.0779,
      "eval_samples_per_second": 24.903,
      "eval_steps_per_second": 3.138,
      "step": 450
    },
    {
      "epoch": 0.8170515097690941,
      "grad_norm": 0.4616064429283142,
      "learning_rate": 0.0001092929292929293,
      "loss": 1.9351,
      "step": 460
    },
    {
      "epoch": 0.8348134991119005,
      "grad_norm": 0.49273183941841125,
      "learning_rate": 0.00010727272727272728,
      "loss": 1.9776,
      "step": 470
    },
    {
      "epoch": 0.8525754884547069,
      "grad_norm": 0.3487735390663147,
      "learning_rate": 0.00010525252525252525,
      "loss": 1.8812,
      "step": 480
    },
    {
      "epoch": 0.8703374777975134,
      "grad_norm": 0.47138649225234985,
      "learning_rate": 0.00010323232323232324,
      "loss": 2.0191,
      "step": 490
    },
    {
      "epoch": 0.8880994671403197,
      "grad_norm": 0.4369531571865082,
      "learning_rate": 0.00010121212121212122,
      "loss": 1.9835,
      "step": 500
    },
    {
      "epoch": 0.8880994671403197,
      "eval_loss": 1.8438178300857544,
      "eval_runtime": 20.0139,
      "eval_samples_per_second": 24.983,
      "eval_steps_per_second": 3.148,
      "step": 500
    },
    {
      "epoch": 0.9058614564831261,
      "grad_norm": 0.36504456400871277,
      "learning_rate": 9.919191919191919e-05,
      "loss": 1.8566,
      "step": 510
    },
    {
      "epoch": 0.9236234458259325,
      "grad_norm": 0.38900303840637207,
      "learning_rate": 9.717171717171718e-05,
      "loss": 1.9531,
      "step": 520
    },
    {
      "epoch": 0.9413854351687388,
      "grad_norm": 0.4357396066188812,
      "learning_rate": 9.515151515151515e-05,
      "loss": 1.9263,
      "step": 530
    },
    {
      "epoch": 0.9591474245115453,
      "grad_norm": 0.41320428252220154,
      "learning_rate": 9.313131313131314e-05,
      "loss": 1.8232,
      "step": 540
    },
    {
      "epoch": 0.9769094138543517,
      "grad_norm": 0.38949260115623474,
      "learning_rate": 9.111111111111112e-05,
      "loss": 1.8897,
      "step": 550
    },
    {
      "epoch": 0.9769094138543517,
      "eval_loss": 1.8431960344314575,
      "eval_runtime": 20.0276,
      "eval_samples_per_second": 24.966,
      "eval_steps_per_second": 3.146,
      "step": 550
    },
    {
      "epoch": 0.9946714031971581,
      "grad_norm": 0.3894442915916443,
      "learning_rate": 8.90909090909091e-05,
      "loss": 1.9593,
      "step": 560
    },
    {
      "epoch": 1.0124333925399644,
      "grad_norm": 0.35994380712509155,
      "learning_rate": 8.707070707070707e-05,
      "loss": 1.9322,
      "step": 570
    },
    {
      "epoch": 1.030195381882771,
      "grad_norm": 0.36774152517318726,
      "learning_rate": 8.505050505050506e-05,
      "loss": 1.8518,
      "step": 580
    },
    {
      "epoch": 1.0479573712255772,
      "grad_norm": 0.5447892546653748,
      "learning_rate": 8.303030303030304e-05,
      "loss": 1.8951,
      "step": 590
    },
    {
      "epoch": 1.0657193605683837,
      "grad_norm": 0.3946532607078552,
      "learning_rate": 8.101010101010101e-05,
      "loss": 1.9756,
      "step": 600
    },
    {
      "epoch": 1.0657193605683837,
      "eval_loss": 1.83990478515625,
      "eval_runtime": 20.0424,
      "eval_samples_per_second": 24.947,
      "eval_steps_per_second": 3.143,
      "step": 600
    },
    {
      "epoch": 1.0834813499111902,
      "grad_norm": 0.4686700403690338,
      "learning_rate": 7.898989898989899e-05,
      "loss": 1.951,
      "step": 610
    },
    {
      "epoch": 1.1012433392539964,
      "grad_norm": 0.35874369740486145,
      "learning_rate": 7.696969696969696e-05,
      "loss": 1.9236,
      "step": 620
    },
    {
      "epoch": 1.119005328596803,
      "grad_norm": 0.5736156702041626,
      "learning_rate": 7.494949494949495e-05,
      "loss": 1.8884,
      "step": 630
    },
    {
      "epoch": 1.1367673179396092,
      "grad_norm": 0.43021637201309204,
      "learning_rate": 7.292929292929293e-05,
      "loss": 1.9142,
      "step": 640
    },
    {
      "epoch": 1.1545293072824157,
      "grad_norm": 0.3465677499771118,
      "learning_rate": 7.090909090909092e-05,
      "loss": 1.9082,
      "step": 650
    },
    {
      "epoch": 1.1545293072824157,
      "eval_loss": 1.837182879447937,
      "eval_runtime": 20.0176,
      "eval_samples_per_second": 24.978,
      "eval_steps_per_second": 3.147,
      "step": 650
    },
    {
      "epoch": 1.1722912966252221,
      "grad_norm": 0.36688143014907837,
      "learning_rate": 6.88888888888889e-05,
      "loss": 1.9359,
      "step": 660
    },
    {
      "epoch": 1.1900532859680284,
      "grad_norm": 0.31043383479118347,
      "learning_rate": 6.686868686868687e-05,
      "loss": 1.942,
      "step": 670
    },
    {
      "epoch": 1.2078152753108349,
      "grad_norm": 0.4427053928375244,
      "learning_rate": 6.484848484848485e-05,
      "loss": 1.9526,
      "step": 680
    },
    {
      "epoch": 1.2255772646536411,
      "grad_norm": 0.4018913805484772,
      "learning_rate": 6.282828282828284e-05,
      "loss": 1.8389,
      "step": 690
    },
    {
      "epoch": 1.2433392539964476,
      "grad_norm": 0.2775937020778656,
      "learning_rate": 6.080808080808081e-05,
      "loss": 1.9041,
      "step": 700
    },
    {
      "epoch": 1.2433392539964476,
      "eval_loss": 1.8323391675949097,
      "eval_runtime": 20.0421,
      "eval_samples_per_second": 24.947,
      "eval_steps_per_second": 3.143,
      "step": 700
    },
    {
      "epoch": 1.261101243339254,
      "grad_norm": 0.38753843307495117,
      "learning_rate": 5.878787878787879e-05,
      "loss": 1.9154,
      "step": 710
    },
    {
      "epoch": 1.2788632326820604,
      "grad_norm": 0.544209361076355,
      "learning_rate": 5.676767676767677e-05,
      "loss": 1.9397,
      "step": 720
    },
    {
      "epoch": 1.2966252220248669,
      "grad_norm": 0.3443971574306488,
      "learning_rate": 5.474747474747475e-05,
      "loss": 1.7533,
      "step": 730
    },
    {
      "epoch": 1.3143872113676731,
      "grad_norm": 0.41843029856681824,
      "learning_rate": 5.272727272727272e-05,
      "loss": 1.951,
      "step": 740
    },
    {
      "epoch": 1.3321492007104796,
      "grad_norm": 0.37689563632011414,
      "learning_rate": 5.070707070707071e-05,
      "loss": 1.9262,
      "step": 750
    },
    {
      "epoch": 1.3321492007104796,
      "eval_loss": 1.8317054510116577,
      "eval_runtime": 20.0244,
      "eval_samples_per_second": 24.97,
      "eval_steps_per_second": 3.146,
      "step": 750
    },
    {
      "epoch": 1.349911190053286,
      "grad_norm": 0.36165744066238403,
      "learning_rate": 4.868686868686869e-05,
      "loss": 1.9753,
      "step": 760
    },
    {
      "epoch": 1.3676731793960923,
      "grad_norm": 0.3305213153362274,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.9319,
      "step": 770
    },
    {
      "epoch": 1.3854351687388988,
      "grad_norm": 0.5228525996208191,
      "learning_rate": 4.464646464646465e-05,
      "loss": 1.9137,
      "step": 780
    },
    {
      "epoch": 1.403197158081705,
      "grad_norm": 0.40783554315567017,
      "learning_rate": 4.262626262626263e-05,
      "loss": 1.9676,
      "step": 790
    },
    {
      "epoch": 1.4209591474245116,
      "grad_norm": 0.4546385705471039,
      "learning_rate": 4.0606060606060606e-05,
      "loss": 1.9401,
      "step": 800
    },
    {
      "epoch": 1.4209591474245116,
      "eval_loss": 1.8296022415161133,
      "eval_runtime": 20.0593,
      "eval_samples_per_second": 24.926,
      "eval_steps_per_second": 3.141,
      "step": 800
    },
    {
      "epoch": 1.438721136767318,
      "grad_norm": 0.4902808666229248,
      "learning_rate": 3.858585858585859e-05,
      "loss": 1.9436,
      "step": 810
    },
    {
      "epoch": 1.4564831261101243,
      "grad_norm": 0.3950650691986084,
      "learning_rate": 3.656565656565657e-05,
      "loss": 1.9527,
      "step": 820
    },
    {
      "epoch": 1.4742451154529308,
      "grad_norm": 0.4389609098434448,
      "learning_rate": 3.454545454545455e-05,
      "loss": 1.9141,
      "step": 830
    },
    {
      "epoch": 1.492007104795737,
      "grad_norm": 0.3513075113296509,
      "learning_rate": 3.2525252525252524e-05,
      "loss": 1.8775,
      "step": 840
    },
    {
      "epoch": 1.5097690941385435,
      "grad_norm": 0.546334981918335,
      "learning_rate": 3.050505050505051e-05,
      "loss": 1.9581,
      "step": 850
    },
    {
      "epoch": 1.5097690941385435,
      "eval_loss": 1.8272783756256104,
      "eval_runtime": 20.021,
      "eval_samples_per_second": 24.974,
      "eval_steps_per_second": 3.147,
      "step": 850
    },
    {
      "epoch": 1.52753108348135,
      "grad_norm": 0.4973165690898895,
      "learning_rate": 2.8484848484848486e-05,
      "loss": 1.8981,
      "step": 860
    },
    {
      "epoch": 1.5452930728241563,
      "grad_norm": 0.46727049350738525,
      "learning_rate": 2.6464646464646466e-05,
      "loss": 1.9119,
      "step": 870
    },
    {
      "epoch": 1.5630550621669625,
      "grad_norm": 0.4017826020717621,
      "learning_rate": 2.4444444444444445e-05,
      "loss": 1.8552,
      "step": 880
    },
    {
      "epoch": 1.580817051509769,
      "grad_norm": 0.4731304943561554,
      "learning_rate": 2.2424242424242424e-05,
      "loss": 1.9083,
      "step": 890
    },
    {
      "epoch": 1.5985790408525755,
      "grad_norm": 0.3215750455856323,
      "learning_rate": 2.0404040404040407e-05,
      "loss": 1.896,
      "step": 900
    },
    {
      "epoch": 1.5985790408525755,
      "eval_loss": 1.8262243270874023,
      "eval_runtime": 20.0297,
      "eval_samples_per_second": 24.963,
      "eval_steps_per_second": 3.145,
      "step": 900
    },
    {
      "epoch": 1.616341030195382,
      "grad_norm": 0.3462080657482147,
      "learning_rate": 1.8383838383838383e-05,
      "loss": 1.9689,
      "step": 910
    },
    {
      "epoch": 1.6341030195381883,
      "grad_norm": 0.3588506877422333,
      "learning_rate": 1.6363636363636366e-05,
      "loss": 1.9043,
      "step": 920
    },
    {
      "epoch": 1.6518650088809945,
      "grad_norm": 0.35528692603111267,
      "learning_rate": 1.4343434343434345e-05,
      "loss": 1.9205,
      "step": 930
    },
    {
      "epoch": 1.669626998223801,
      "grad_norm": 0.5815038681030273,
      "learning_rate": 1.2323232323232325e-05,
      "loss": 1.8769,
      "step": 940
    },
    {
      "epoch": 1.6873889875666075,
      "grad_norm": 0.28409647941589355,
      "learning_rate": 1.0303030303030304e-05,
      "loss": 1.8991,
      "step": 950
    },
    {
      "epoch": 1.6873889875666075,
      "eval_loss": 1.8255785703659058,
      "eval_runtime": 20.0425,
      "eval_samples_per_second": 24.947,
      "eval_steps_per_second": 3.143,
      "step": 950
    },
    {
      "epoch": 1.705150976909414,
      "grad_norm": 0.3918353319168091,
      "learning_rate": 8.282828282828283e-06,
      "loss": 1.8457,
      "step": 960
    },
    {
      "epoch": 1.7229129662522202,
      "grad_norm": 0.3950922191143036,
      "learning_rate": 6.262626262626263e-06,
      "loss": 1.8858,
      "step": 970
    },
    {
      "epoch": 1.7406749555950265,
      "grad_norm": 0.4130690097808838,
      "learning_rate": 4.242424242424243e-06,
      "loss": 1.975,
      "step": 980
    },
    {
      "epoch": 1.758436944937833,
      "grad_norm": 0.3647906482219696,
      "learning_rate": 2.2222222222222225e-06,
      "loss": 1.9193,
      "step": 990
    },
    {
      "epoch": 1.7761989342806395,
      "grad_norm": 0.47034013271331787,
      "learning_rate": 2.0202020202020202e-07,
      "loss": 1.8311,
      "step": 1000
    },
    {
      "epoch": 1.7761989342806395,
      "eval_loss": 1.8246079683303833,
      "eval_runtime": 20.0416,
      "eval_samples_per_second": 24.948,
      "eval_steps_per_second": 3.143,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7464526131757056.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
